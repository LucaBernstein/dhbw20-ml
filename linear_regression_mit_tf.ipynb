{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent mit Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101) \n",
    "tf.random.set_seed(101) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_W = 2.0 # slope\n",
    "TRUE_b = -3 # intercept\n",
    "\n",
    "NUM_EXAMPLES = 100\n",
    "\n",
    "X = tf.random.normal(shape=(NUM_EXAMPLES,))\n",
    "noise = tf.random.normal(shape=(NUM_EXAMPLES,))\n",
    "y = X * TRUE_W + TRUE_b + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Training Data \n",
    "plt.scatter(X, y) \n",
    "plt.xlabel('x') \n",
    "plt.xlabel('y') \n",
    "plt.title(\"Training Data\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.W = tf.Variable(1.0)\n",
    "        self.b = tf.Variable(1.0)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.W * x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, label=\"true\")\n",
    "plt.scatter(X, model(X), label=\"predicted\")\n",
    "plt.legend();\n",
    "plt.title('Untrainiertes Modell', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, lr=0.01):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(y, model(X))\n",
    "\n",
    "    dW, db = t.gradient(current_loss, [model.W, model.b])\n",
    "    \n",
    "    model.W.assign_sub(lr * dW)\n",
    "    model.b.assign_sub(lr * db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "Ws, bs, Costs = [], [], []\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    Ws.append(model.W.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "\n",
    "    Costs.append(loss(y, model(X)))\n",
    "\n",
    "    train(model, X, y, lr=0.1)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "axs[0].plot(range(epochs), Ws, 'r', range(epochs), bs, 'b')\n",
    "axs[0].plot([TRUE_W] * epochs, 'r--', [TRUE_b] * epochs, 'b--')\n",
    "axs[0].legend(['W', 'b', 'true W', 'true b'])\n",
    "axs[0].set_xticks(np.arange(0,epochs, 5))\n",
    "axs[0].set_xlabel('Iteration')\n",
    "axs[0].set_title('Parameter W und b', fontsize=18)\n",
    "\n",
    "axs[1].plot(range(epochs), Costs, 'g')\n",
    "axs[1].set_xticks(np.arange(0,epochs, 5))\n",
    "axs[1].set_xlabel('Iteration')\n",
    "axs[1].set_ylabel('Cost')\n",
    "axs[1].axhline(0, c='grey');\n",
    "axs[1].set_title('Cost Function vs Iteration', fontsize=18);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, label=\"true\")\n",
    "plt.scatter(X, model(X), label=\"predicted\")\n",
    "plt.legend();\n",
    "plt.title('Trainiertes Modell', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dhbw20': conda)",
   "language": "python",
   "name": "python37664bitdhbw20conda4e9f90a409f24fc4a1b2fdf8774acce3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
