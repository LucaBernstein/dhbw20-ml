{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine Transformation\n",
    "\n",
    "Affine Transformationen sind Transformationen des Raums, bei denen bestimmte geometrische Eigenschaften erhalten bleiben.\n",
    "Lose formuliert:\n",
    "\n",
    "- Punkte einer Geraden werden wieder auf eine Gerade abgebildet\n",
    "- Parallele Geraden bleiben parallel\n",
    "- Das Verhältnis dreier Punkte einer Geraden bleibt erhalten\n",
    "\n",
    "Affine Transformationen kann man mittels Matrixmultiplikation darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot(X, fig, ax):\n",
    "    ax.scatter(X[:,0], X[:,1], alpha=0.5)\n",
    "    ax.set_xlabel(r'$x_1$')\n",
    "    ax.set_ylabel(r'$x_2$')\n",
    "    ax.axis('equal');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erzeugen wir uns zunächst mal eine Punktwolke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 200\n",
    "\n",
    "rng = np.random.default_rng(50)\n",
    "X_id = rng.standard_normal(size=(m,2))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "plot(X_id, fig, ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Punktwolke können wir durch Multiplikation mit einer 2x2 Matrix verzerren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = np.pi/2\n",
    "rot = [[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]]\n",
    "shear = [[1, 2], [0, 1]]\n",
    "stretchX = [[2, 0],[0, 1]]\n",
    "stretchY = [[1, 0],[0, 1.5]]\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(15,10))\n",
    "\n",
    "def plotTransformed(label, input, transformation, ax):\n",
    "    box = np.asarray([[x,y] for x in np.linspace(-4,4, 20) for y in np.linspace(-4,4, 20)]).T\n",
    "    box_transformed = np.dot(box.T, transformation)\n",
    "    data = np.dot(input, transformation)\n",
    "    A = data[:, 0]\n",
    "    B = data[:, 1]\n",
    "    ax.axis('equal')\n",
    "    ax.set(xlim=[-10,10], ylim=[-10, 10])\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(box_transformed[:,0], box_transformed[:,1], s=1, c='grey', alpha=0.5);\n",
    "    ax.scatter(A, B, alpha=0.6);\n",
    "\n",
    "plotTransformed('Identität', X_id, np.identity(2), ax=axs[0, 0])\n",
    "plotTransformed('Rotation', X_id, rot, ax=axs[0, 1])\n",
    "plotTransformed('Shear', X_id, shear, ax=axs[0, 2])\n",
    "plotTransformed('Stretch X', X_id, stretchX, ax=axs[1, 0])\n",
    "plotTransformed('Stretch Y', X_id, stretchY, ax=axs[1, 1])\n",
    "\n",
    "combined = np.dot(np.dot(stretchX, stretchY), np.dot(rot, shear))\n",
    "plotTransformed('Combined', X_id, combined, ax=axs[1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nehmen wir doch mal die letzte Punktwolke und ermitteln dafür im folgenden die Kovarianzmatrix und deren Eigenvektoren.\n",
    "\n",
    "Hier also unsere Punktwolke nochmal größer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dot(X_id, combined)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "plotTransformed('Verzerrte Punktwolke', X_id, combined, ax=ax);\n",
    "ax.set(xlim=[-12, 12], ylim=[-12, 12]);\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skalierung auf Standard\n",
    "\n",
    "Wir standardisieren die Features durch Entfernen des Mittelwerts und Skalierung auf Einheitsvarianz.\n",
    "\n",
    "Der Standardwert einer Stichprobe x wird berechnet als:\n",
    "\n",
    "$$z=\\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "wobei $\\mu$ der Mittelwert der Trainingsstichproben und $\\sigma$ die Standardabweichung der Trainingsstichproben ist.\n",
    "\n",
    "Zentrierung und Skalierung erfolgen unabhängig für jedes Merkmal, indem die relevanten Statistiken über die Stichproben im Trainingsset berechnet werden. Mittelwert und Standardabweichung werden dann gespeichert, um bei späteren Daten mittels Transformation verwendet zu werden.\n",
    "\n",
    "Die Standardisierung eines Datensatzes ist eine häufige Anforderung für viele Schätzer des maschinellen Lernens: Sie könnten sich schlecht verhalten, wenn die einzelnen Merkmale nicht mehr oder weniger wie normalverteilte Standarddaten aussehen (z.B. Gaußsch mit Mittelwert 0 und Einheitsvarianz).\n",
    "\n",
    "Beispielsweise gehen viele Elemente, die in der Cost-Function eines Lernalgorithmus verwendet werden (wie die L1- und L2-Regularisierer von linearen Modellen) davon aus, dass alle Merkmale um 0 zentriert sind und Varianzen in gleicher Größenordnung haben. Wenn ein Merkmal eine Varianz hat, die um Größenordnungen größer ist als andere, könnte es die Zielfunktion dominieren und den Schätzer unfähig machen, von anderen Merkmalen zu lernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "print(f'Skalierer: {scaler}')\n",
    "\n",
    "X_std = scaler.transform(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "plotTransformed('Skalierte verzerrte Punktwolke', X_std, np.identity(2), ax=ax);\n",
    "ax.set(xlim=[-4, 4], ylim=[-4, 4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kovarianzmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = np.mean(X_std, axis=0)\n",
    "print(f'Means: {mean_vec}')\n",
    "\n",
    "cov_mat = (X_std - mean_vec).T.dot(X_std - mean_vec) / (X_std.shape[0]-1)\n",
    "\n",
    "display(Markdown('Kovarianz Matrix: \\n\\n' + r'$Cov(x_1, x_2)= \\begin{bmatrix} \\sigma_{1,1}\\;\\sigma_{1,2} \\\\ \\sigma_{2,1}\\;\\sigma_{2,2} \\end{bmatrix}= \\begin{bmatrix}' + '{:.3f}'.format(cov_mat[0,0]) + '\\;' + '{:.3f}'.format(cov_mat[0,1]) + r' \\\\ ' + '{:.3f}'.format(cov_mat[1,0]) + '\\,' + '{:.3f}'.format(cov_mat[1,1]) + ' \\end{bmatrix}$' % cov_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvektoren\n",
    "\n",
    "Ein **Eigenvektor** einer Matrix ist ein vom Nullvektor verschiedener Vektor, dessen Richtung durch die Abbildung - sprich Multiplikation mit der Matrix - nicht verändert wird. Ein Eigenvektor wird also nur skaliert und man bezeichnet den Skalierungsfaktor als **Eigenwert** der Abbildung.\n",
    "\n",
    "Mit einer Matrix $A$ und einem Eigenvektor $v\\neq0$ gilt dann $$A v = \\lambda v$$\n",
    "\n",
    "Für kleine Matrizen kann man die Eigenvektoren noch exakt ermitteln, ansonsten werden numerische Methoden angewandt. Die Wahl der Methode ist abhängig von der Art der Matrix (insbesondere ob sparse oder dicht besetzt).\n",
    "\n",
    "> Array Slicing in Python: Array slicing hat folgende Syntax: a[start:stop:step].\n",
    ">\n",
    "> Wenn ein Parameter nicht angegeben ist, dann werden folgende Defaults verwendet: \n",
    "> - step=1\n",
    "> - falls step > 0: start=0, stop=length\n",
    "> - falls step < 0: start=length-1, stop=-1\n",
    ">\n",
    "> d.h. der Ausdruck a[::-1] bedeutet: Nimm das gesamte Array, aber durchlaufe es rückwärts.\n",
    ">\n",
    "> Hier nutzen wir das, um eine **absteigende Sortierung** zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_, eig_vecs_ = np.linalg.eig(cov_mat)\n",
    "\n",
    "eig_vals = np.sort(eig_vals_)[::-1]\n",
    "eig_vecs = eig_vecs_[:, eig_vals_.argsort()[::-1]].T # np.linalg.eig gibt Spalten-Eigenvektoren zurück, daher transponieren\n",
    "\n",
    "print(f'''\n",
    "Eigenwerte:\n",
    "{eig_vals}\n",
    "\n",
    "Eigenvektoren:\n",
    "{eig_vecs}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können noch prüfen, ob die Gleichung $Av=\\lambda v$ tatsächlich hält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cov_mat.dot(eig_vecs) - eig_vals*eig_vecs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax, c='black'):\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0,\n",
    "                    color=c\n",
    "                   )\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "for length, vector in zip(eig_vals, eig_vecs): \n",
    "    v = vector * 2 * np.sqrt(length)\n",
    "    draw_vector([0,0], [0.0] + v, ax)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Eigenvektoren der Kovarianzmatrix bilden ein gutes Koordinatensystem, welches der Verteilung der Punktwolke folgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(21,10))\n",
    "\n",
    "# zunächst noch mal unsere Punktewolke\n",
    "plotTransformed('Skalierte verzerrte Punktwolke', X_std, np.identity(2), ax=axs[0]);\n",
    "axs[0].set(xlim=[-4, 4], ylim=[-4, 4]);\n",
    "\n",
    "cs = ['green', 'red']\n",
    "for idx, (length, vector) in enumerate(zip(eig_vals, eig_vecs)):\n",
    "    v = vector * 2 * np.sqrt(length)\n",
    "    draw_vector([0,0], [0.0] + v, axs[0], cs[idx])\n",
    "\n",
    "# und jetzt die Transformation durch PCA\n",
    "X_pca = X_std.dot(eig_vecs)\n",
    "\n",
    "plotTransformed('Eigenvektorielle Koordinaten', X_std, eig_vecs, ax=axs[1]);\n",
    "draw_vector([0,0], [2*np.sqrt(eig_vals[0]), 0], axs[1], cs[0])\n",
    "draw_vector([0,0], [0, 2*np.sqrt(eig_vals[1])], axs[1], cs[1])\n",
    "\n",
    "axs[1].set(xlabel='Eigenvektor 1', ylabel='Eigenvektor 2')\n",
    "axs[1].set(xlim=[-4, 4], ylim=[-4, 4]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Und das ist genau der Ansatz der PCA:**\n",
    "\n",
    "- ermittle ein neues Koordinatensystem, wobei die Koordinaten nach der Größe ihres Beitrags sortiert sind\n",
    "- wähle dann die ersten k Koordinaten aus, so dass noch hinreichend Information vorhanden ist\n",
    "- und projiziere dann den Featureraum auf diese k Dimensionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dhbw20': conda)",
   "language": "python",
   "name": "python37664bitdhbw20conda4e9f90a409f24fc4a1b2fdf8774acce3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
